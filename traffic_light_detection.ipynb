{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZmVTVtXEihd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_TRAFFIC_LIGHT = 10\n",
        "\n",
        "def load_model(model_name):\n",
        "    url = 'http://download.tensorflow.org/models/object_detection/' + model_name + '.tar.gz'\n",
        "    model_dir = tf.keras.utils.get_file(fname=model_name, untar=True, origin=url)\n",
        "\n",
        "    print(\"Model path: \", model_dir)\n",
        "    model_dir = pathlib.Path(model_dir) / \"saved_model\"\n",
        "    model = tf.saved_model.load(str(model_dir))\n",
        "    model = model.signatures['serving_default']\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "_cOXg8nTEydu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_image(model, file_name, model_traffic_lights=None):\n",
        "    img_bgr = cv2.imread(file_name)\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    input_tensor = tf.convert_to_tensor(img_rgb)\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # Run inference\n",
        "    output = model(input_tensor)\n",
        "\n",
        "    print(\"num_detections:\", output['num_detections'], int(output['num_detections']))\n",
        "\n",
        "    # Converts the tensors to NumPy array\n",
        "    num_detections = int(output.pop('num_detections'))\n",
        "    output = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in output.items()}\n",
        "    output['num_detections'] = num_detections\n",
        "\n",
        "    print('Detection classes:', output['detection_classes'])\n",
        "    print('Detection Boxes:', output['detection_boxes'])\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    output['detection_classes'] = output['detection_classes'].astype(np.int64)\n",
        "    output['boxes'] = [\n",
        "        {\"y\": int(box[0] * img_rgb.shape[0]), \"x\": int(box[1] * img_rgb.shape[1]), \"y2\": int(box[2] * img_rgb.shape[0]),\n",
        "         \"x2\": int(box[3] * img_rgb.shape[1])} for box in output['detection_boxes']]\n",
        "\n",
        "\n",
        "\n",
        "    return img_rgb, output, file_name\n"
      ],
      "metadata": {
        "id": "m_6E0HdGGnGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_ssd_coco():\n",
        "    return load_model(\"ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Fo7aiPq-FO9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "\n",
        "\n",
        "files = object_detection.find_files('traffic_input_full/*.png')\n",
        "model = object_detection.load_ssd_coco()\n",
        "\n",
        "num_traffic_lights = 0\n",
        "num_files = 0\n",
        "\n",
        "print(\"Files:\", len(files))\n",
        "\n",
        "for file in files:\n",
        "    (img_rgb, out, file_name) = detect_image(model, file)\n",
        "    if (num_files % 10) == 0:\n",
        "        print(\"Files processed:\", num_files)\n",
        "        print(\"Traffic lights found: \", num_traffic_lights)\n",
        "    num_files = num_files + 1\n",
        "    for idx in range(len(out['boxes'])):\n",
        "        obj_class = out[\"detection_classes\"][idx]\n",
        "        if obj_class == object_detection.LABEL_TRAFFIC_LIGHT:\n",
        "            box = out[\"boxes\"][idx]\n",
        "            traffic_light = img_rgb[box[\"y\"]:box[\"y2\"], box[\"x\"]:box[\"x2\"]]\n",
        "            traffic_light = cv2.cvtColor(traffic_light, cv2.COLOR_RGB2BGR)\n",
        "            plt.imshow(traffic_light)\n",
        "            cv2.imshow('example',out)\n",
        "            #cv2.imwrite(\"traffic_input_cropped/\" + str(num_traffic_lights) + \".png\", traffic_light)\n",
        "            num_traffic_lights = num_traffic_lights + 1\n",
        "\n",
        "print(\"Traffic lights found:\", num_traffic_lights)"
      ],
      "metadata": {
        "id": "9uCxrUFDF66D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras.utils import to_categorical\n",
        "import collections\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.optimizers import Adam, Adadelta\n",
        "from keras.losses import categorical_crossentropy\n",
        "import sys\n",
        "import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "AWVl07NRHZP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Transfer(n_classes, freeze_layers=True):\n",
        "    print('Loading InceptionV3')\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "    print('InceptionV3 loaded.')\n",
        "\n",
        "    print('Layers: ', len(base_model.layers))\n",
        "    print(\"Shape:\", base_model.output_shape[1:])\n",
        "    print(\"Shape:\", base_model.output_shape)\n",
        "    print(\"Shape:\", base_model.outputs)\n",
        "\n",
        "    base_model.summary()\n",
        "\n",
        "    top_model = Sequential()\n",
        "    top_model.add(base_model)\n",
        "    top_model.add(GlobalAveragePooling2D())\n",
        "    top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(1024, activation='relu'))\n",
        "    top_model.add(BatchNormalization())\n",
        "    top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(512, activation='relu'))\n",
        "    top_model.add(Dropout(0.5))\n",
        "    top_model.add(Dense(128, activation='relu'))\n",
        "    top_model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "    # model = Model(input=base_model.input, output=top_model)\n",
        "\n",
        "    if freeze_layers:\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    return top_model\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=5, width_shift_range=[-10, -5, -2, 0, 2, 5, 10],\n",
        "                             zoom_range=[0.7, 1.5], height_shift_range=[-10, -5, -2, 0, 2, 5, 10],\n",
        "                             horizontal_flip=True)\n",
        "\n",
        "shape = (299, 299)\n",
        "img_0_green = object_detection.load_images_rgb(\"traffic_dataset/0_green/*\", shape)\n",
        "img_1_yellow = object_detection.load_images_rgb(\"traffic_dataset/1_yellow/*\", shape)\n",
        "img_2_red = object_detection.load_images_rgb(\"traffic_dataset/2_red/*\", shape)\n",
        "img_3_not_traffic_light = object_detection.load_images_rgb(\"traffic_dataset/3_not/*\", shape)\n",
        "\n",
        "labels = [0] * len(img_0_green)\n",
        "labels.extend([1] * len(img_1_yellow))\n",
        "labels.extend([2] * len(img_2_red))\n",
        "labels.extend([3] * len(img_3_not_traffic_light))\n",
        "\n",
        "labels_np = np.ndarray(shape=(len(labels), 4))\n",
        "images_np = np.ndarray(shape=(len(labels), shape[0], shape[1], 3))\n",
        "\n",
        "img_all = []\n",
        "img_all.extend(img_0_green)\n",
        "img_all.extend(img_1_yellow)\n",
        "img_all.extend(img_2_red)\n",
        "img_all.extend(img_3_not_traffic_light)\n",
        "\n",
        "assert len(img_all) == len(labels)\n",
        "\n",
        "img_all = [preprocess_input(img) for img in img_all]\n",
        "(img_all, labels) = object_detection.double_shuffle(img_all, labels)\n",
        "\n",
        "for idx in range(len(labels)):\n",
        "    images_np[idx] = img_all[idx]\n",
        "    labels_np[idx] = labels[idx]\n",
        "\n",
        "print(\"Images: \", len(img_all))\n",
        "print(\"Labels: \", len(labels))\n",
        "\n",
        "for idx in range(len(labels_np)):\n",
        "    labels_np[idx] = np.array(to_categorical(labels[idx], 4))\n",
        "\n",
        "idx_split = int(len(labels_np) * 0.8)\n",
        "x_train = images_np[0:idx_split]\n",
        "x_valid = images_np[idx_split:]\n",
        "y_train = labels_np[0:idx_split]\n",
        "y_valid = labels_np[idx_split:]\n",
        "\n",
        "cnt = collections.Counter(labels)\n",
        "print('Labels:', cnt)\n",
        "n = len(labels)\n",
        "print('0:', cnt[0])\n",
        "print('1:', cnt[1])\n",
        "print('2:', cnt[2])\n",
        "print('3:', cnt[3])\n",
        "class_weight = {0: n / cnt[0], 1: n / cnt[1], 2: n / cnt[2], 3: n / cnt[3]}\n",
        "print('Class weight:', class_weight)\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"traffic.h5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
        "early_stopping = EarlyStopping(min_delta=0.0005, patience=15, verbose=1)\n",
        "\n",
        "model = Transfer(4)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "it_train = datagen.flow(x_train, y_train, batch_size=32)\n",
        "\n",
        "model.compile(loss=categorical_crossentropy, optimizer=Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0),\n",
        "              metrics=['accuracy'])\n",
        "history_object = model.fit(it_train, epochs=250, validation_data=(x_valid, y_valid), shuffle=True,\n",
        "                           callbacks=[checkpoint, early_stopping], class_weight=class_weight)\n",
        "\n",
        "show_history(history_object)\n",
        "score = model.evaluate(x_valid, y_valid, verbose=0)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])\n",
        "\n",
        "print('Saving validation')\n",
        "\n",
        "for idx in range(len(x_valid)):\n",
        "    img_as_ar = np.array([x_valid[idx]])\n",
        "    prediction = model.predict(img_as_ar)\n",
        "    label = np.argmax(prediction)\n",
        "    file_name = \"out_valid/\" + str(label) + \"/\" + str(idx) + \"_\" + str(label) + \"_\" + str(np.argmax(str(y_valid[idx]))) + \".jpg\"\n",
        "    img = img_as_ar[0]\n",
        "    img = object_detection.reverse_preprocess_inception(img)\n",
        "    cv2.imwrite(file_name, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "63jfAQbuHalw",
        "outputId": "e6acb8c9-42e2-4bba-e973-f6029350aa4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-46cd064da5f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mimg_0_green\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_images_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"traffic_dataset/0_green/*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mimg_1_yellow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_images_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"traffic_dataset/1_yellow/*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mimg_2_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_images_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"traffic_dataset/2_red/*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'object_detection' is not defined"
          ]
        }
      ]
    }
  ]
}